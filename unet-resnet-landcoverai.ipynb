{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2275679,"sourceType":"datasetVersion","datasetId":1370551},{"sourceId":192552314,"sourceType":"kernelVersion"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"import cv2\nimport glob\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib\nimport shutil\nimport random\nimport time\nfrom pathlib import Path\n\nsns.set_style(\"dark\")\n\nDATA_ROOT = \"../input/landcoverai\"","metadata":{"execution":{"iopub.status.busy":"2024-09-27T10:58:31.396839Z","iopub.execute_input":"2024-09-27T10:58:31.397615Z","iopub.status.idle":"2024-09-27T10:58:33.150740Z","shell.execute_reply.started":"2024-09-27T10:58:31.397557Z","shell.execute_reply":"2024-09-27T10:58:33.149647Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"OUTPUT_DIR = os.path.join(os.getcwd(), \"output\")\nIMGS_DIR = \"../input/landcoverai/images\"\nMASKS_DIR = \"../input/landcoverai/masks\"\nDATA_ROOT = \"../input/landcoverai\"\nIMG_PATHS = glob.glob(os.path.join(IMGS_DIR, \"*.tif\"))\nMASK_PATHS = glob.glob(os.path.join(MASKS_DIR, \"*.tif\"))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T03:55:59.823151Z","iopub.execute_input":"2024-09-25T03:55:59.824154Z","iopub.status.idle":"2024-09-25T03:55:59.877374Z","shell.execute_reply.started":"2024-09-25T03:55:59.824113Z","shell.execute_reply":"2024-09-25T03:55:59.876656Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"images_list = list(glob.glob(os.path.join(DATA_ROOT, \"images\", \"*.tif\")))\nsamples = [0,1,2,3]\nfig, ax = plt.subplots(figsize = (9,9), nrows = 2, ncols =2)\nfor i, sample in enumerate(samples):\n    r,c = divmod(i,2)\n    ax[r,c].imshow(cv2.imread(images_list[sample])/255)\n    ax[r,c].axis(\"off\")\nplt.suptitle(\"Sample (s) of high resolution images\", fontsize = 15)\nplt.tight_layout(pad=0.8)\n# plt.savefig(\"Samples.png\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-25T03:56:02.292986Z","iopub.execute_input":"2024-09-25T03:56:02.293368Z","iopub.status.idle":"2024-09-25T03:57:05.949712Z","shell.execute_reply.started":"2024-09-25T03:56:02.293330Z","shell.execute_reply":"2024-09-25T03:57:05.948321Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Splitting","metadata":{}},{"cell_type":"code","source":"IMAGE_SIZE = 512\n\ndef split_images(TARGET_SIZE = IMAGE_SIZE):\n    \"\"\"\n    A function to split the aerial images into squared images of\n    size equal to TARGET_SIZE. Stores the new images into\n    a directory named output, located in working directory.\n    \"\"\"\n    tic = time.time()\n    print(f\"Splitting the images...\\n\")\n    img_paths = glob.glob(os.path.join(IMGS_DIR, \"*.tif\"))\n    mask_paths = glob.glob(os.path.join(MASKS_DIR, \"*.tif\"))\n\n    img_paths.sort()\n    mask_paths.sort()\n    \n    if Path(OUTPUT_DIR).exists() and Path(OUTPUT_DIR).is_dir():\n        shutil.rmtree(OUTPUT_DIR)\n    os.makedirs(OUTPUT_DIR)\n    for i, (img_path, mask_path) in enumerate(zip(img_paths, mask_paths)):\n        img_filename = os.path.splitext(os.path.basename(img_path))[0]\n        mask_filename = os.path.splitext(os.path.basename(mask_path))[0]\n        img = cv2.imread(img_path)\n        mask = cv2.imread(mask_path)\n\n        assert img_filename == mask_filename and img.shape[:2] == mask.shape[:2]\n\n        k = 0\n        for y in range(0, img.shape[0], TARGET_SIZE):\n            for x in range(0, img.shape[1], TARGET_SIZE):\n                img_tile = img[y:y + TARGET_SIZE, x:x + TARGET_SIZE]\n                mask_tile = mask[y:y + TARGET_SIZE, x:x + TARGET_SIZE]\n\n                if img_tile.shape[0] == TARGET_SIZE and img_tile.shape[1] == TARGET_SIZE:\n                    out_img_path = os.path.join(OUTPUT_DIR, \"{}_{}.jpg\".format(img_filename, k))\n                    cv2.imwrite(out_img_path, img_tile)\n\n                    out_mask_path = os.path.join(OUTPUT_DIR, \"{}_{}_m.png\".format(mask_filename, k))\n                    cv2.imwrite(out_mask_path, mask_tile)\n\n                k += 1\n\n        print(\"Processed {} {}/{}\".format(img_filename, i + 1, len(img_paths)))\n    mins,sec = divmod(time.time()-tic,60)\n    print(f\"Execution completed in {mins} minutes and {sec:.2f} seconds.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-25T03:57:05.951520Z","iopub.execute_input":"2024-09-25T03:57:05.951862Z","iopub.status.idle":"2024-09-25T03:57:05.964924Z","shell.execute_reply.started":"2024-09-25T03:57:05.951827Z","shell.execute_reply":"2024-09-25T03:57:05.964015Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMAGE_SIZE = 512\nsplit_images(TARGET_SIZE = IMAGE_SIZE)","metadata":{"execution":{"iopub.status.busy":"2024-09-25T03:57:05.966233Z","iopub.execute_input":"2024-09-25T03:57:05.966666Z","iopub.status.idle":"2024-09-25T03:58:51.585724Z","shell.execute_reply.started":"2024-09-25T03:57:05.966615Z","shell.execute_reply":"2024-09-25T03:58:51.584817Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels_cmap = matplotlib.colors.ListedColormap([\"#000000\", \"#A9A9A9\",\n        \"#8B8680\", \"#D3D3D3\", \"#FFFFFF\"])\n\ndef visualize_dataset(num_samples = 8, seed = 42,\n                     w = 10, h = 10, nrows = 4, ncols = 4, save_title = None,\n                     pad = 0.8, indices = None):\n    \"\"\"\n    A function to visualize the images of the dataset along with their\n    corresponding masks.\n    \"\"\"\n    data_list = list(glob.glob(os.path.join(OUTPUT_DIR, \"*.jpg\")))\n    if indices == None:\n        np.random.seed(seed)\n        indices = np.random.randint(low = 0, high = len(data_list),\n                                   size = num_samples)\n    sns.set_style(\"white\")\n    fig, ax = plt.subplots(figsize = (h,w), nrows = num_samples//2,\n                           ncols = 4)\n    for i, idx in enumerate(indices):\n        r,rem = divmod(i,2)\n        img = cv2.imread(data_list[idx])/255\n        mask_pt = data_list[indices[i]].split(\".jpg\")[0] + \"_m.png\"\n        mask = cv2.imread(mask_pt)[:,:,1]\n        ax[r,2*rem].imshow(img)\n        ax[r,2*rem].set_title(\"Sample\"+str(i+1))\n        ax[r,2*rem+1].imshow(mask, cmap = labels_cmap, interpolation = None,\n                            vmin = -0.5, vmax = 4.5)\n        ax[r,2*rem+1].set_title(\"Mask\" + str(i+1))\n    plt.suptitle(\"Samples of 512 x 512 images\", fontsize = 20)\n    plt.tight_layout(pad = 0.8)\n    if save_title is not None:\n        plt.savefig(save_title + \".png\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-25T03:58:51.588305Z","iopub.execute_input":"2024-09-25T03:58:51.588619Z","iopub.status.idle":"2024-09-25T03:58:51.599658Z","shell.execute_reply.started":"2024-09-25T03:58:51.588586Z","shell.execute_reply":"2024-09-25T03:58:51.598563Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualize_dataset(num_samples = 8, w = 12, h = 12, pad = 1.4,\n                 save_title = \"Visualize_dataset\", indices = [0,1,17,20,29,5,6,7])","metadata":{"execution":{"iopub.status.busy":"2024-09-25T03:58:51.600655Z","iopub.execute_input":"2024-09-25T03:58:51.600968Z","iopub.status.idle":"2024-09-25T03:58:59.450824Z","shell.execute_reply.started":"2024-09-25T03:58:51.600936Z","shell.execute_reply":"2024-09-25T03:58:59.449340Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass SegmentationDataset(Dataset):\n    \"\"\"\n    The main class that handles the dataset. Reads the images from\n    OUTPUT_DIR, handles the data augmentation transformations, and converts\n    the numpy images to tensors. Filters out images where 90% or more of\n    the mask pixels are unlabeled (labeled as 0).\n    \"\"\"\n    def __init__(self, mode=\"train\", ratio=None, transforms=None, seed=42):\n        self.mode = mode\n        self.transforms = transforms\n        self.output_dir = OUTPUT_DIR\n        self.data_root = DATA_ROOT\n        self.unlabeled_threshold = 0.9  # 90% threshold for unlabeled pixels\n        \n        if mode in [\"train\", \"test\", \"val\"]:\n            with open(os.path.join(self.data_root, self.mode + \".txt\")) as f:\n                self.img_names = f.read().splitlines()\n                if ratio is not None:\n                    print(f\"Using {100 * ratio:.2f}% of the initial {mode} set --> {int(ratio * len(self.img_names))}|{len(self.img_names)}\")\n                    np.random.seed(seed)\n                    self.indices = np.random.randint(low=0, high=len(self.img_names),\n                                                     size=int(ratio * len(self.img_names)))\n                else:\n                    print(f\"Using the whole {mode} set --> {len(self.img_names)}\")\n                    self.indices = list(range(len(self.img_names)))\n        else:\n            raise ValueError(f\"mode should be either train, val or test ... not {self.mode}.\")\n\n    def __len__(self):\n        return len(self.indices)\n\n    def __getitem__(self, item):\n        while True:\n            # Load image and mask\n            img_path = os.path.join(self.output_dir, self.img_names[self.indices[item]] + \".jpg\")\n            mask_path = os.path.join(self.output_dir, self.img_names[self.indices[item]] + \"_m.png\")\n            \n            img = cv2.imread(img_path)\n            mask = cv2.imread(mask_path)\n            \n            # Extract the label mask (assuming the labels are stored in the second channel)\n            label = mask[:, :, 1]\n            \n            # Calculate the percentage of unlabeled (0) pixels\n            unlabeled_pixels = np.sum(label == 0)\n            total_pixels = label.size\n            unlabeled_ratio = unlabeled_pixels / total_pixels\n\n            # If the image has more than 90% unlabeled pixels, skip it and pick another\n            if unlabeled_ratio < self.unlabeled_threshold:\n                break\n            else:\n                # If we need to skip this image, pick another random one\n                item = np.random.randint(0, len(self.indices))\n\n        if self.transforms is None:\n            img = np.transpose(img, (2, 0, 1))  # Convert to channel-first format (C, H, W)\n        else:\n            transformed = self.transforms(image=img, mask=label)\n            img = np.transpose(transformed[\"image\"], (2, 0, 1))\n            label = transformed[\"mask\"]\n\n        return torch.tensor(img, dtype=torch.float32) / 255, torch.tensor(label, dtype=torch.int64)","metadata":{"execution":{"iopub.status.busy":"2024-09-25T03:58:59.452054Z","iopub.execute_input":"2024-09-25T03:58:59.452372Z","iopub.status.idle":"2024-09-25T03:59:01.310691Z","shell.execute_reply.started":"2024-09-25T03:58:59.452336Z","shell.execute_reply":"2024-09-25T03:59:01.309821Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2024-09-25T03:59:01.311781Z","iopub.execute_input":"2024-09-25T03:59:01.312232Z","iopub.status.idle":"2024-09-25T03:59:01.340174Z","shell.execute_reply.started":"2024-09-25T03:59:01.312197Z","shell.execute_reply":"2024-09-25T03:59:01.339170Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataloader","metadata":{}},{"cell_type":"code","source":"train_set = SegmentationDataset(mode = \"train\")\ntrain_dloader = DataLoader(train_set,batch_size = 8,num_workers =2)\n\nclass_dist = {\"background\":0, \"building\":0,\n                     \"woodland\":0, \"water\":0, \"road\":0}\nlabel_mapping = {0: \"background\", 1: \"building\",\n                2: \"woodland\", 3: \"water\", 4: \"road\"}\n\nfor img,mask in train_dloader:\n    for class_label in label_mapping.keys():\n        class_dist[label_mapping[class_label]] += mask[mask == class_label].numpy().size","metadata":{"execution":{"iopub.status.busy":"2024-09-25T03:59:01.341450Z","iopub.execute_input":"2024-09-25T03:59:01.341812Z","iopub.status.idle":"2024-09-25T04:00:12.856089Z","shell.execute_reply.started":"2024-09-25T03:59:01.341768Z","shell.execute_reply":"2024-09-25T04:00:12.854935Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# temp_list = sorted([(l,s) for (l,s) in class_dist.items()], key= lambda x: x[1])\n# labels = [x[0] for x in temp_list]\n# support = [x[1] for x in temp_list]\n\n# sns.set_style(\"dark\")\n# fig, ax = plt.subplots(figsize = (10,8))\n# ax.bar(labels, support, color = \"#36454F\")\n# ax.set_yscale(\"log\")\n# ax.set_title(\"The distribution of the training set with 512x512 images\",\n#             fontsize = 17)\n# ax.set_ylabel(\"Number of pixels\")\n# plt.savefig(\"Barplt.png\")\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:22:54.793171Z","iopub.execute_input":"2024-08-14T19:22:54.793892Z","iopub.status.idle":"2024-08-14T19:22:55.529199Z","shell.execute_reply.started":"2024-08-14T19:22:54.793861Z","shell.execute_reply":"2024-08-14T19:22:55.528271Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Augmentation","metadata":{}},{"cell_type":"code","source":"import albumentations as A","metadata":{"execution":{"iopub.status.busy":"2024-09-25T04:00:12.858139Z","iopub.execute_input":"2024-09-25T04:00:12.858485Z","iopub.status.idle":"2024-09-25T04:00:13.932859Z","shell.execute_reply.started":"2024-09-25T04:00:12.858446Z","shell.execute_reply":"2024-09-25T04:00:13.931834Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from albumentations import (\n    GaussianBlur, ElasticTransform, GridDistortion, OpticalDistortion,\n    ShiftScaleRotate, ChannelShuffle, CLAHE, ISONoise, CoarseDropout,\n    MotionBlur, RandomFog, RandomRain, RandomSnow, Solarize, Equalize, \n    InvertImg, Posterize, RandomSunFlare, RandomShadow, RandomBrightnessContrast\n)\nimport cv2\nimport glob\nimport os\nimport matplotlib.pyplot as plt\n\n# Define the additional Albumentations transformations\nadditional_transforms = [\n    GaussianBlur(blur_limit=(3, 7), p=1),\n    ElasticTransform(alpha=1, sigma=50, alpha_affine=None, p=1),\n    GridDistortion(p=1),\n    OpticalDistortion(distort_limit=0.5, shift_limit=0.5, p=1),\n    ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, p=1),\n    ChannelShuffle(p=1),\n    CLAHE(p=1),\n    ISONoise(p=1),\n    CoarseDropout(max_holes=8, max_height=16, max_width=16, p=1),\n    MotionBlur(blur_limit=7, p=1),\n    RandomFog(fog_coef_lower=0.1, fog_coef_upper=0.3, alpha_coef=0.08, p=1),\n    RandomRain(slant_lower=-10, slant_upper=10, drop_length=20, drop_color=(200, 200, 200), p=1),\n    RandomSnow(snow_point_lower=0.1, snow_point_upper=0.3, p=1),\n    Solarize(p=1),\n    Equalize(p=1),\n    InvertImg(p=1),\n    Posterize(num_bits=4, p=1),\n    RandomSunFlare(flare_roi=(0.0, 0.0, 1.0, 0.5), angle_lower=0.0, p=1),\n    RandomShadow(shadow_roi=(0.0, 0.5, 1.0, 1.0), p=1),\n    RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1)\n]\n\nadditional_transforms_names = [\n    \"GaussianBlur\", \"ElasticTransform\", \"GridDistortion\", \n    \"OpticalDistortion\", \"ShiftScaleRotate\", \"ChannelShuffle\", \n    \"CLAHE\", \"ISONoise\", \"CoarseDropout\", \"MotionBlur\", \n    \"RandomFog\", \"RandomRain\", \"RandomSnow\", \"Solarize\", \n    \"Equalize\", \"InvertImg\", \"Posterize\", \"RandomSunFlare\", \n    \"RandomShadow\", \"RandomBrightnessContrast\"\n]\n\n# Read the NUM_SAMPLE sample in the training set\nNUM_SAMPLE = 4\ntrainpath_list = list(glob.glob(os.path.join(os.getcwd(), \"output\", \"*.jpg\")))\nimg = cv2.imread(trainpath_list[NUM_SAMPLE])\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert image to RGB\n\n# Create a figure to display original and transformed images\nfig, ax = plt.subplots(figsize=(16, 12), nrows=4, ncols=5)\n\n# Display original image\nax[0, 0].imshow(img)\nax[0, 0].axis(\"off\")\nax[0, 0].set_title(\"True image\")\n\n# Apply and display transformations\ncount = 0\nfor i in range(4):\n    for j in range(5):\n        if i == 0 and j == 0:\n            continue  # Skip the original image slot\n        transformed_img = additional_transforms[count](image=img)[\"image\"]\n        ax[i, j].imshow(transformed_img)\n        ax[i, j].axis(\"off\")\n        ax[i, j].set_title(additional_transforms_names[count])\n        count += 1\n\nplt.suptitle(\"Data Augmentation\", fontsize=17)\nplt.tight_layout(pad=1)\nplt.savefig(\"augmentations.png\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T04:00:13.936809Z","iopub.execute_input":"2024-09-25T04:00:13.937295Z","iopub.status.idle":"2024-09-25T04:00:22.901361Z","shell.execute_reply.started":"2024-09-25T04:00:13.937259Z","shell.execute_reply":"2024-09-25T04:00:22.899927Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import albumentations as A\n\n# Configuring the set of transformations\ntransforms = A.Compose([\n\n    # Color augmentations\n    A.OneOf([\n        A.HueSaturationValue(hue_shift_limit=40, sat_shift_limit=40, val_shift_limit=30, p=1),\n        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.5, p=1),\n        A.RGBShift(r_shift_limit=20, g_shift_limit=20, b_shift_limit=20, p=1),\n        A.ToSepia(p=1),  # Convert image to sepia tone\n        A.Solarize(threshold=128, p=1)  # Invert pixel intensities above a threshold\n    ], p=0.5),  # Apply one of the color-based augmentations\n\n    # Spatial augmentations\n    A.OneOf([\n        A.RandomRotate90(p=1),  # Rotate the image 90 degrees randomly\n        A.HorizontalFlip(p=1),  # Flip the image horizontally\n        A.VerticalFlip(p=1),  # Flip the image vertically\n        A.Transpose(p=1),  # Transpose image by swapping axes\n        A.RandomSizedCrop(min_max_height=(248, 512), height=512, width=512, p=1),  # Randomly crop and resize\n        A.Perspective(scale=(0.05, 0.1), p=1)  # Perspective transformation\n    ], p=0.5),  # Apply one of the spatial augmentations\n\n    # Warping/Distortion augmentations\n    A.OneOf([\n        A.ElasticTransform(alpha=1, sigma=50, alpha_affine=None, p=1),\n        A.GridDistortion(num_steps=5, distort_limit=0.3, p=1),  # Grid-based warping of the image\n        A.OpticalDistortion(distort_limit=0.5, shift_limit=0.5, p=1),  # Optical lens effect distortion\n        A.PiecewiseAffine(scale=(0.03, 0.05), p=1)  # Piecewise affine transformation for localized distortions\n    ], p=0.5),\n\n    # Combination of shifting, scaling, and rotating\n    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, p=0.5),\n\n    # Blur and noise\n    A.OneOf([\n        A.GaussianBlur(blur_limit=(3, 7), p=1),  # Apply Gaussian blur\n        A.MotionBlur(blur_limit=7, p=1),  # Simulate motion blur\n        A.MedianBlur(blur_limit=7, p=1),  # Apply median blur\n    ], p=0.5),\n    \n    # Noise augmentation\n    A.OneOf([\n        A.ISONoise(p=1),  # Add noise similar to high ISO photographs\n        A.GaussNoise(var_limit=(10.0, 50.0), p=1)  # Add Gaussian noise\n    ], p=0.5),\n\n    # CLAHE for contrast enhancement\n    A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.5),\n\n    # Dropout for occlusion simulation\n    A.OneOf([\n        A.CoarseDropout(max_holes=8, max_height=16, max_width=16, p=1),  # Randomly drop out portions of the image\n    ], p=0.5)\n])\n\n# This will apply a combination of the specified augmentations, with probabilities of 0.5 for each group.\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T04:00:22.902873Z","iopub.execute_input":"2024-09-25T04:00:22.903174Z","iopub.status.idle":"2024-09-25T04:00:23.092360Z","shell.execute_reply.started":"2024-09-25T04:00:22.903142Z","shell.execute_reply":"2024-09-25T04:00:23.091369Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# U-net Models","metadata":{}},{"cell_type":"code","source":"!pip install segmentation-models-pytorch\n\nimport segmentation_models_pytorch as smp","metadata":{"execution":{"iopub.status.busy":"2024-09-27T10:58:45.866364Z","iopub.execute_input":"2024-09-27T10:58:45.866961Z","iopub.status.idle":"2024-09-27T10:59:14.299031Z","shell.execute_reply.started":"2024-09-27T10:58:45.866918Z","shell.execute_reply":"2024-09-27T10:59:14.297683Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:26:57.399722Z","iopub.status.idle":"2024-09-24T13:26:57.400020Z","shell.execute_reply.started":"2024-09-24T13:26:57.399866Z","shell.execute_reply":"2024-09-24T13:26:57.399881Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ntarget_names = np.array([\"background\", \"building\", \"woodland\", \"water\", \"road\"])\n\n# Loss function - Mean IoU loss\nloss_fn = smp.losses.JaccardLoss(mode = \"multiclass\",\n                                classes = 5).to(device)\n\n# Hyperparameters\nbatch_size = 8\nepochs = 30\nlr = 5e-5\n\n# Preparing datasets and DataLoaders\ntrain_set = SegmentationDataset(mode = \"train\", transforms = transforms,\n                               ratio = 0.6)\ntest_set = SegmentationDataset(mode = \"test\")\nval_set = SegmentationDataset(mode = \"val\", ratio = 0.7)\n\ntrain_dloader = DataLoader(train_set, batch_size = batch_size,\n                           shuffle = True, num_workers = 2)\ntest_dloader = DataLoader(test_set, batch_size = batch_size, num_workers = 2)\nval_dloader = DataLoader(val_set, batch_size=batch_size, num_workers = 2)","metadata":{"execution":{"iopub.status.busy":"2024-09-25T04:00:45.418066Z","iopub.execute_input":"2024-09-25T04:00:45.418391Z","iopub.status.idle":"2024-09-25T04:00:45.443655Z","shell.execute_reply.started":"2024-09-25T04:00:45.418357Z","shell.execute_reply":"2024-09-25T04:00:45.442782Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from landcoverutil import training_loop","metadata":{"execution":{"iopub.status.busy":"2024-09-25T04:00:45.444941Z","iopub.execute_input":"2024-09-25T04:00:45.445627Z","iopub.status.idle":"2024-09-25T04:00:46.425212Z","shell.execute_reply.started":"2024-09-25T04:00:45.445581Z","shell.execute_reply":"2024-09-25T04:00:46.424413Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Resnet50","metadata":{}},{"cell_type":"code","source":"model_resnet50 = smp.Unet(encoder_name = \"resnet50\",\n                encoder_weights = \"imagenet\",\n                classes = 5).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T14:39:06.029479Z","iopub.execute_input":"2024-09-24T14:39:06.030488Z","iopub.status.idle":"2024-09-24T14:39:07.331100Z","shell.execute_reply.started":"2024-09-24T14:39:06.030438Z","shell.execute_reply":"2024-09-24T14:39:07.330157Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\ntrainable_params = count_parameters(model_resnet50)\nprint(f\"Total trainable parameters: {trainable_params}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-24T14:39:07.332449Z","iopub.execute_input":"2024-09-24T14:39:07.333192Z","iopub.status.idle":"2024-09-24T14:39:07.340333Z","shell.execute_reply.started":"2024-09-24T14:39:07.333143Z","shell.execute_reply":"2024-09-24T14:39:07.339397Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from landcoverutil import training_loop\n\nepochs = 50\n\n# Training starts!\ntraining_loop(model_resnet50, train_dloader, val_dloader, epochs, lr, loss_fn, mod_epochs =1,\n             regularization = \"L2\", reg_lambda = 1e-6, early_stopping = False,\n             patience = 5, verbose = True, model_title = \"UNet with Resnet encoder\", save = True,\n             stopping_criterion = \"loss\")","metadata":{"execution":{"iopub.status.busy":"2024-09-24T14:39:07.343410Z","iopub.execute_input":"2024-09-24T14:39:07.343702Z","iopub.status.idle":"2024-09-24T20:36:57.676841Z","shell.execute_reply.started":"2024-09-24T14:39:07.343670Z","shell.execute_reply":"2024-09-24T20:36:57.675654Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# labels_cmap = matplotlib.colors.ListedColormap([\"#FFFFFF\", \"#C9E4CA\", \"#F7DC6F\", \"#F2C464\", \"#FFC080\"])\n\nlabels_cmap = matplotlib.colors.ListedColormap([\"#000000\", \"#A9A9A9\",\n        \"#8B8680\", \"#D3D3D3\", \"#FFFFFF\"])\n\ndef visualize_preds(model, train_set, title, num_samples = 4, seed = 42,\n                    w = 10, h = 10, save_title = None, indices = None):\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    np.random.seed(seed)\n    if indices == None:\n        indices = np.random.randint(low = 0, high = len(train_set),\n                                    size = num_samples)\n    sns.set_style(\"white\")\n    fig, ax = plt.subplots(figsize = (w,h),\n                           nrows = num_samples, ncols = 3)\n    model.eval()\n    for i,idx in enumerate(indices):\n        X,y = train_set[idx]\n        X_dash = X[None,:,:,:].to(device)\n        preds = torch.argmax(model(X_dash), dim = 1)\n        preds = torch.squeeze(preds).detach().cpu().numpy()\n\n        mirrored_img = np.fliplr(np.transpose(X.cpu(), (2,1,0)))  # Apply horizontal flip\n        rotated_mirrored_img = np.rot90(mirrored_img, k=1)  # Rotate 180 degrees (two 90-degree rotations)\n\n        # Display the mirrored and rotated image\n        ax[i,0].imshow(rotated_mirrored_img)\n        ax[i,0].set_title(\"True Image\")\n        ax[i,0].axis(\"off\")\n        ax[i,1].imshow(y, cmap = labels_cmap, interpolation = None,\n                      vmin = -0.5, vmax = 4.5)\n        ax[i,1].set_title(\"Labels\")\n        ax[i,1].axis(\"off\")\n        ax[i,2].imshow(preds, cmap = labels_cmap, interpolation = None,\n                      vmin = -0.5, vmax = 4.5)\n        ax[i,2].set_title(\"Predictions\")\n        ax[i,2].axis(\"off\")\n    fig.suptitle(title, fontsize = 20)\n    plt.tight_layout()\n    if save_title is not None:\n        plt.savefig(save_title + \".png\")\n    plt.show()\n    \n    \nvisualize_preds(model_resnet50, test_set, title = \"Predictions - UNet+Resnet50\",\n               save_title = \"UNet+Resnet50\", h = 12, w = 12, indices = [957,961,1476,1578])","metadata":{"execution":{"iopub.status.busy":"2024-09-24T20:39:24.219441Z","iopub.execute_input":"2024-09-24T20:39:24.220369Z","iopub.status.idle":"2024-09-24T20:39:28.020536Z","shell.execute_reply.started":"2024-09-24T20:39:24.220327Z","shell.execute_reply":"2024-09-24T20:39:28.019586Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torchmetrics\nimport torchvision.transforms.functional as TF\nimport torch.nn.functional as F\n\ndef segmentation_test_loop_with_metrics(model, test_loader, num_classes=5, device=\"cpu\"):\n    \"\"\"\n    Runs a test loop for the model on a test dataset, calculates precision, recall, F1-score, accuracy, IoU, and confusion matrix.\n\n    Args:\n        model: The trained model to evaluate.\n        test_loader: Dataloader for the test dataset.\n        num_classes: The number of classes in the dataset.\n        device: Device to run the evaluation on (\"cpu\" or \"cuda\").\n\n    Returns:\n        precision: Precision score for each class.\n        recall: Recall score for each class.\n        f1_score: F1 score for each class.\n        confusion_matrix: Computed confusion matrix.\n        acc: Overall accuracy.\n        jaccard: Jaccard index (IoU) for the entire test set.\n    \"\"\"\n\n    # Initialize metrics\n    precision = torchmetrics.Precision(task='multiclass', num_classes=num_classes, average=None).to(device)\n    recall = torchmetrics.Recall(task='multiclass', num_classes=num_classes, average=None).to(device)\n    f1_score = torchmetrics.F1Score(task='multiclass', num_classes=num_classes, average=None).to(device)\n    \n    # Additional metrics\n    acc = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes, average=\"micro\", multidim_average=\"global\").to(device)\n    jaccard = torchmetrics.JaccardIndex(task='multiclass', num_classes=num_classes).to(device)\n    confusion_matrix = torchmetrics.ConfusionMatrix(task='multiclass', num_classes=num_classes).to(device)\n\n    model.eval()\n\n    class_probs = {i: 0 for i in range(num_classes)}\n    num_samples = {i: 0 for i in range(num_classes)}\n\n    for X, y in test_loader:\n        X = X.to(device)\n        y = y.to(device)\n\n        with torch.no_grad():\n            logits = F.softmax(model(X), dim=1)  # Apply softmax to get probabilities\n            aggr = torch.max(logits, dim=1)  # Get the predicted class (index of the max probability)\n            preds = aggr[1]  # Predictions\n            probs = aggr[0]  # Probabilities of the predicted classes\n\n            # Update per-class probabilities and number of samples\n            for label in class_probs.keys():\n                class_probs[label] += probs[preds == label].sum().item()\n                num_samples[label] += (preds == label).sum().item()\n\n            # Update metrics\n            precision.update(preds, y)\n            recall.update(preds, y)\n            f1_score.update(preds, y)\n            acc.update(preds, y)\n            jaccard.update(preds, y)\n            confusion_matrix.update(preds, y)  # Update the confusion matrix with predictions and ground truth\n\n    # Normalize class probabilities\n    for label in class_probs.keys():\n        if num_samples[label] > 0:\n            class_probs[label] /= num_samples[label]\n\n    # Compute final metrics\n    precision_result = precision.compute()\n    recall_result = recall.compute()\n    f1_score_result = f1_score.compute()\n    acc_result = acc.compute()\n    jaccard_result = jaccard.compute()\n    confusion_matrix_result = confusion_matrix.compute()\n\n    return precision_result, recall_result, f1_score_result, confusion_matrix_result, acc_result, jaccard_result, class_probs\n\n\n# Call the function and get the metrics\nprecision, recall, f1_score, confusion_matrix, acc, jaccard, class_probs = segmentation_test_loop_with_metrics(\n    model=model_resnet50, test_loader=test_dloader, num_classes=5, device=device)\n\n# Print the metrics\nfor i in range(len(precision)):\n    print(f\"Class {i}: Precision: {precision[i].item():.4f}, Recall: {recall[i].item():.4f}, F1-Score: {f1_score[i].item():.4f}\")\nprint(f\"Confusion Matrix:\\n {confusion_matrix.cpu().numpy()}\")\nprint(f\"Accuracy: {acc.item():.4f}\")\nprint(f\"Jaccard Index (Mean IoU): {jaccard.item():.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-24T20:39:47.411453Z","iopub.execute_input":"2024-09-24T20:39:47.411867Z","iopub.status.idle":"2024-09-24T20:40:20.148942Z","shell.execute_reply.started":"2024-09-24T20:39:47.411823Z","shell.execute_reply":"2024-09-24T20:40:20.147733Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport torchmetrics\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import roc_curve, auc\n\n# Class labels for the segmentation task\nclasses = ['Building', 'Woodland', 'Water', 'Road', 'Unlabeled']\n\ndef segmentation_test_loop_with_metrics(model, test_loader, num_classes=5, device=\"cpu\"):\n    \"\"\"\n    Runs a test loop for the model on a test dataset, calculates precision, recall, F1-score, accuracy, IoU, and confusion matrix.\n    Additionally, calculates the per-class metrics and returns them for evaluation.\n    \n    Args:\n        model: The trained model to evaluate.\n        test_loader: Dataloader for the test dataset.\n        num_classes: The number of classes in the dataset.\n        device: Device to run the evaluation on (\"cpu\" or \"cuda\").\n\n    Returns:\n        precision: Precision score for each class.\n        recall: Recall score for each class.\n        f1_score: F1 score for each class.\n        confusion_matrix: Computed confusion matrix.\n        acc: Overall accuracy.\n        jaccard: Jaccard index (IoU) for the entire test set.\n        class_probs: The average probability for each class.\n    \"\"\"\n\n    # Initialize metrics\n    precision = torchmetrics.Precision(task='multiclass', num_classes=num_classes, average=None).to(device)\n    recall = torchmetrics.Recall(task='multiclass', num_classes=num_classes, average=None).to(device)\n    f1_score = torchmetrics.F1Score(task='multiclass', num_classes=num_classes, average=None).to(device)\n    \n    # Additional metrics\n    acc = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes, average=\"micro\", multidim_average=\"global\").to(device)\n    jaccard = torchmetrics.JaccardIndex(task='multiclass', num_classes=num_classes).to(device)\n    confusion_matrix = torchmetrics.ConfusionMatrix(task='multiclass', num_classes=num_classes).to(device)\n\n    model.eval()\n\n    class_probs = {i: 0 for i in range(num_classes)}\n    num_samples = {i: 0 for i in range(num_classes)}\n\n    for X, y in test_loader:\n        X = X.to(device)\n        y = y.to(device)\n\n        with torch.no_grad():\n            logits = F.softmax(model(X), dim=1)  # Apply softmax to get probabilities\n            aggr = torch.max(logits, dim=1)  # Get the predicted class (index of the max probability)\n            preds = aggr[1]  # Predictions\n            probs = aggr[0]  # Probabilities of the predicted classes\n\n            # Update per-class probabilities and number of samples\n            for label in class_probs.keys():\n                class_probs[label] += probs[preds == label].sum().item()\n                num_samples[label] += (preds == label).sum().item()\n\n            # Update metrics\n            precision.update(preds, y)\n            recall.update(preds, y)\n            f1_score.update(preds, y)\n            acc.update(preds, y)\n            jaccard.update(preds, y)\n            confusion_matrix.update(preds, y)  # Update the confusion matrix with predictions and ground truth\n\n    # Normalize class probabilities\n    for label in class_probs.keys():\n        if num_samples[label] > 0:\n            class_probs[label] /= num_samples[label]\n\n    # Compute final metrics\n    precision_result = precision.compute()\n    recall_result = recall.compute()\n    f1_score_result = f1_score.compute()\n    acc_result = acc.compute()\n    jaccard_result = jaccard.compute()\n    confusion_matrix_result = confusion_matrix.compute()\n\n    return precision_result, recall_result, f1_score_result, confusion_matrix_result, acc_result, jaccard_result, class_probs\n\n\ndef plot_confusion_matrix(confusion_matrix, class_names):\n    \"\"\"\n    Plot the confusion matrix using Seaborn heatmap.\n    Args:\n        confusion_matrix: The confusion matrix to plot.\n        class_names: List of class names corresponding to the matrix indices.\n    \"\"\"\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(confusion_matrix.cpu().numpy(), annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted Label')\n    plt.ylabel('True Label')\n    plt.show()\n\n\ndef plot_multiclass_roc(model, test_loader, num_classes=5, device=\"cpu\"):\n    \"\"\"\n    Function to plot ROC curves for multi-class classification.\n    \n    Args:\n        model: The trained model.\n        test_loader: Dataloader for the test dataset.\n        num_classes: Number of classes.\n        device: Device to run the evaluation.\n    \"\"\"\n    y_true = []\n    y_scores = []\n\n    model.eval()\n    with torch.no_grad():\n        for X, y in test_loader:\n            X = X.to(device)\n            y = y.to(device)\n\n            logits = F.softmax(model(X), dim=1)\n            y_true.append(y.cpu())\n            y_scores.append(logits.cpu())\n\n    # Concatenate all batches\n    y_true = torch.cat(y_true).numpy()\n    y_scores = torch.cat(y_scores).numpy()\n\n    # Binarize labels for ROC\n    y_true_binarized = label_binarize(y_true, classes=[i for i in range(num_classes)])\n    \n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n\n    for i in range(num_classes):\n        fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], y_scores[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # Plotting all ROC curves\n    plt.figure(figsize=(10, 8))\n    for i in range(num_classes):\n        plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve of class {classes[i]} (area = {roc_auc[i]:.2f})')\n    \n    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic for Multi-Class')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n\n# Call the function to get metrics\nprecision, recall, f1_score, confusion_matrix, acc, jaccard, class_probs = segmentation_test_loop_with_metrics(\n    model=model_resnet50, test_loader=test_dloader, num_classes=5, device=device)\n\n# Print the metrics with class names\nprint(f\"{'Class':<15}{'Precision':<10}{'Recall':<10}{'F1-Score':<10}\")\nfor i, class_name in enumerate(classes):\n    print(f\"{class_name:<15}{precision[i].item():<10.4f}{recall[i].item():<10.4f}{f1_score[i].item():<10.4f}\")\nprint(f\"\\nAccuracy: {acc.item():.4f}\")\nprint(f\"Mean IoU (Jaccard Index): {jaccard.item():.4f}\")\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-24T20:40:20.151985Z","iopub.execute_input":"2024-09-24T20:40:20.152660Z","iopub.status.idle":"2024-09-24T20:40:52.645330Z","shell.execute_reply.started":"2024-09-24T20:40:20.152605Z","shell.execute_reply":"2024-09-24T20:40:52.644120Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot the confusion matrix\nplot_confusion_matrix(confusion_matrix, classes)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T20:40:52.646830Z","iopub.execute_input":"2024-09-24T20:40:52.647164Z","iopub.status.idle":"2024-09-24T20:40:53.096199Z","shell.execute_reply.started":"2024-09-24T20:40:52.647128Z","shell.execute_reply":"2024-09-24T20:40:53.095261Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_multiclass_roc(model, test_loader, num_classes=5, device=\"cpu\"):\n    \"\"\"\n    Function to plot ROC curves for multi-class classification.\n    \n    Args:\n        model: The trained model.\n        test_loader: Dataloader for the test dataset.\n        num_classes: Number of classes.\n        device: Device to run the evaluation.\n    \"\"\"\n    y_true = []\n    y_scores = []\n\n    model.eval()\n    with torch.no_grad():\n        for X, y in test_loader:\n            X = X.to(device)\n            y = y.to(device)\n\n            logits = F.softmax(model(X), dim=1)  # Get probability scores\n            y_true.append(y.cpu())  # True labels\n            y_scores.append(logits.cpu())  # Predicted probabilities\n\n    # Concatenate all batches to create full arrays of true labels and scores\n    y_true = torch.cat(y_true).numpy()  # Shape: (N,) for N samples\n    y_scores = torch.cat(y_scores).numpy()  # Shape: (N, num_classes)\n\n    # Binarize labels for ROC (needed for multi-class)\n    y_true_binarized = label_binarize(y_true, classes=[i for i in range(num_classes)])  # Shape: (N, num_classes)\n    \n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n\n    for i in range(num_classes):\n        fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], y_scores[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # Plotting all ROC curves\n    plt.figure(figsize=(10, 8))\n    for i in range(num_classes):\n        plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve of class {classes[i]} (area = {roc_auc[i]:.2f})')\n    \n    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic for Multi-Class')\n    plt.legend(loc=\"lower right\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T20:45:22.507771Z","iopub.execute_input":"2024-09-24T20:45:22.508187Z","iopub.status.idle":"2024-09-24T20:45:22.547366Z","shell.execute_reply.started":"2024-09-24T20:45:22.508140Z","shell.execute_reply":"2024-09-24T20:45:22.546444Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot ROC curve for multi-class classifier\nplot_multiclass_roc(model=model_resnet50, test_loader=test_dloader, num_classes=5, device=device)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T20:45:26.659543Z","iopub.execute_input":"2024-09-24T20:45:26.660329Z","iopub.status.idle":"2024-09-24T20:45:26.980626Z","shell.execute_reply.started":"2024-09-24T20:45:26.660287Z","shell.execute_reply":"2024-09-24T20:45:26.979250Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model_resnet50.state_dict(), \"resnet50.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-09-24T07:29:12.231656Z","iopub.status.idle":"2024-09-24T07:29:12.232119Z","shell.execute_reply.started":"2024-09-24T07:29:12.231926Z","shell.execute_reply":"2024-09-24T07:29:12.231969Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Resnet 101","metadata":{}},{"cell_type":"code","source":"model_resnet101 = smp.Unet(encoder_name = \"resnet101\",\n                encoder_weights = \"imagenet\",\n                classes = 5).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T20:57:33.476265Z","iopub.execute_input":"2024-09-24T20:57:33.476952Z","iopub.status.idle":"2024-09-24T20:57:37.368266Z","shell.execute_reply.started":"2024-09-24T20:57:33.476905Z","shell.execute_reply":"2024-09-24T20:57:37.367413Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\ntrainable_params = count_parameters(model_resnet101)\nprint(f\"Total trainable parameters: {trainable_params}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-24T20:57:37.369601Z","iopub.execute_input":"2024-09-24T20:57:37.370317Z","iopub.status.idle":"2024-09-24T20:57:37.378646Z","shell.execute_reply.started":"2024-09-24T20:57:37.370267Z","shell.execute_reply":"2024-09-24T20:57:37.377563Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epochs = 50\n\n# Training starts!\ntraining_loop(model_resnet101, train_dloader, val_dloader, epochs, lr, loss_fn, mod_epochs =1,\n             regularization = \"L2\", reg_lambda = 1e-6, early_stopping = False,\n             patience = 5, verbose = True, model_title = \"UNet with Resnet encoder 101\", save = True,\n             stopping_criterion = \"loss\")","metadata":{"execution":{"iopub.status.busy":"2024-09-24T20:57:37.379822Z","iopub.execute_input":"2024-09-24T20:57:37.380129Z","iopub.status.idle":"2024-09-25T03:10:58.980230Z","shell.execute_reply.started":"2024-09-24T20:57:37.380095Z","shell.execute_reply":"2024-09-25T03:10:58.979225Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# torch.save(model_resnet101.state_dict(), \"resnet101.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-09-25T03:10:58.985189Z","iopub.execute_input":"2024-09-25T03:10:58.985633Z","iopub.status.idle":"2024-09-25T03:10:58.990972Z","shell.execute_reply.started":"2024-09-25T03:10:58.985597Z","shell.execute_reply":"2024-09-25T03:10:58.990108Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def visualize_preds(model, train_set, title, num_samples = 4, seed = 42,\n                    w = 10, h = 10, save_title = None, indices = None):\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    np.random.seed(seed)\n    if indices == None:\n        indices = np.random.randint(low = 0, high = len(train_set),\n                                    size = num_samples)\n    sns.set_style(\"white\")\n    fig, ax = plt.subplots(figsize = (w,h),\n                           nrows = num_samples, ncols = 3)\n    model.eval()\n    for i,idx in enumerate(indices):\n        X,y = train_set[idx]\n        X_dash = X[None,:,:,:].to(device)\n        preds = torch.argmax(model(X_dash), dim = 1)\n        preds = torch.squeeze(preds).detach().cpu().numpy()\n\n        mirrored_img = np.fliplr(np.transpose(X.cpu(), (2,1,0)))  # Apply horizontal flip\n        rotated_mirrored_img = np.rot90(mirrored_img, k=1)  # Rotate 180 degrees (two 90-degree rotations)\n\n        # Display the mirrored and rotated image\n        ax[i,0].imshow(rotated_mirrored_img)\n        ax[i,0].set_title(\"True Image\")\n        ax[i,0].axis(\"off\")\n        ax[i,1].imshow(y, cmap = labels_cmap, interpolation = None,\n                      vmin = -0.5, vmax = 4.5)\n        ax[i,1].set_title(\"Labels\")\n        ax[i,1].axis(\"off\")\n        ax[i,2].imshow(preds, cmap = labels_cmap, interpolation = None,\n                      vmin = -0.5, vmax = 4.5)\n        ax[i,2].set_title(\"Predictions\")\n        ax[i,2].axis(\"off\")\n    fig.suptitle(title, fontsize = 20)\n    plt.tight_layout()\n    if save_title is not None:\n        plt.savefig(save_title + \".png\")\n    plt.show()\n\nvisualize_preds(model_resnet101, test_set, title = \"Predictions - UNet+Resnet101\",\n               save_title = \"UNet+Resnet101\", h = 12, w = 12, indices = [957,961,1476,1578])","metadata":{"execution":{"iopub.status.busy":"2024-09-25T03:47:16.111506Z","iopub.execute_input":"2024-09-25T03:47:16.112105Z","iopub.status.idle":"2024-09-25T03:47:20.168074Z","shell.execute_reply.started":"2024-09-25T03:47:16.112037Z","shell.execute_reply":"2024-09-25T03:47:20.167104Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torchmetrics\nimport torchvision.transforms.functional as TF\nimport torch.nn.functional as F\n\ndef segmentation_test_loop_with_metrics(model, test_loader, num_classes=5, device=\"cpu\"):\n    \"\"\"\n    Runs a test loop for the model on a test dataset, calculates precision, recall, F1-score, accuracy, IoU, and confusion matrix.\n\n    Args:\n        model: The trained model to evaluate.\n        test_loader: Dataloader for the test dataset.\n        num_classes: The number of classes in the dataset.\n        device: Device to run the evaluation on (\"cpu\" or \"cuda\").\n\n    Returns:\n        precision: Precision score for each class.\n        recall: Recall score for each class.\n        f1_score: F1 score for each class.\n        confusion_matrix: Computed confusion matrix.\n        acc: Overall accuracy.\n        jaccard: Jaccard index (IoU) for the entire test set.\n    \"\"\"\n\n    # Initialize metrics\n    precision = torchmetrics.Precision(task='multiclass', num_classes=num_classes, average=None).to(device)\n    recall = torchmetrics.Recall(task='multiclass', num_classes=num_classes, average=None).to(device)\n    f1_score = torchmetrics.F1Score(task='multiclass', num_classes=num_classes, average=None).to(device)\n    \n    # Additional metrics\n    acc = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes, average=\"micro\", multidim_average=\"global\").to(device)\n    jaccard = torchmetrics.JaccardIndex(task='multiclass', num_classes=num_classes).to(device)\n    confusion_matrix = torchmetrics.ConfusionMatrix(task='multiclass', num_classes=num_classes).to(device)\n\n    model.eval()\n\n    class_probs = {i: 0 for i in range(num_classes)}\n    num_samples = {i: 0 for i in range(num_classes)}\n\n    for X, y in test_loader:\n        X = X.to(device)\n        y = y.to(device)\n\n        with torch.no_grad():\n            logits = F.softmax(model(X), dim=1)  # Apply softmax to get probabilities\n            aggr = torch.max(logits, dim=1)  # Get the predicted class (index of the max probability)\n            preds = aggr[1]  # Predictions\n            probs = aggr[0]  # Probabilities of the predicted classes\n\n            # Update per-class probabilities and number of samples\n            for label in class_probs.keys():\n                class_probs[label] += probs[preds == label].sum().item()\n                num_samples[label] += (preds == label).sum().item()\n\n            # Update metrics\n            precision.update(preds, y)\n            recall.update(preds, y)\n            f1_score.update(preds, y)\n            acc.update(preds, y)\n            jaccard.update(preds, y)\n            confusion_matrix.update(preds, y)  # Update the confusion matrix with predictions and ground truth\n\n    # Normalize class probabilities\n    for label in class_probs.keys():\n        if num_samples[label] > 0:\n            class_probs[label] /= num_samples[label]\n\n    # Compute final metrics\n    precision_result = precision.compute()\n    recall_result = recall.compute()\n    f1_score_result = f1_score.compute()\n    acc_result = acc.compute()\n    jaccard_result = jaccard.compute()\n    confusion_matrix_result = confusion_matrix.compute()\n\n    return precision_result, recall_result, f1_score_result, confusion_matrix_result, acc_result, jaccard_result, class_probs\n\n\n# Call the function and get the metrics\nprecision, recall, f1_score, confusion_matrix, acc, jaccard, class_probs = segmentation_test_loop_with_metrics(\n    model=model_resnet101, test_loader=test_dloader, num_classes=5, device=device)\n\n# Print the metrics\nfor i in range(len(precision)):\n    print(f\"Class {i}: Precision: {precision[i].item():.4f}, Recall: {recall[i].item():.4f}, F1-Score: {f1_score[i].item():.4f}\")\nprint(f\"Confusion Matrix:\\n {confusion_matrix.cpu().numpy()}\")\nprint(f\"Accuracy: {acc.item():.4f}\")\nprint(f\"Jaccard Index (Mean IoU): {jaccard.item():.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T03:11:02.892948Z","iopub.execute_input":"2024-09-25T03:11:02.893291Z","iopub.status.idle":"2024-09-25T03:11:44.284363Z","shell.execute_reply.started":"2024-09-25T03:11:02.893255Z","shell.execute_reply":"2024-09-25T03:11:44.283123Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport torchmetrics\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import roc_curve, auc\n\n# Class labels for the segmentation task\nclasses = ['Building', 'Woodland', 'Water', 'Road', 'Unlabeled']\n\ndef segmentation_test_loop_with_metrics(model, test_loader, num_classes=5, device=\"cpu\"):\n    \"\"\"\n    Runs a test loop for the model on a test dataset, calculates precision, recall, F1-score, accuracy, IoU, and confusion matrix.\n    Additionally, calculates the per-class metrics and returns them for evaluation.\n    \n    Args:\n        model: The trained model to evaluate.\n        test_loader: Dataloader for the test dataset.\n        num_classes: The number of classes in the dataset.\n        device: Device to run the evaluation on (\"cpu\" or \"cuda\").\n\n    Returns:\n        precision: Precision score for each class.\n        recall: Recall score for each class.\n        f1_score: F1 score for each class.\n        confusion_matrix: Computed confusion matrix.\n        acc: Overall accuracy.\n        jaccard: Jaccard index (IoU) for the entire test set.\n        class_probs: The average probability for each class.\n    \"\"\"\n\n    # Initialize metrics\n    precision = torchmetrics.Precision(task='multiclass', num_classes=num_classes, average=None).to(device)\n    recall = torchmetrics.Recall(task='multiclass', num_classes=num_classes, average=None).to(device)\n    f1_score = torchmetrics.F1Score(task='multiclass', num_classes=num_classes, average=None).to(device)\n    \n    # Additional metrics\n    acc = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes, average=\"micro\", multidim_average=\"global\").to(device)\n    jaccard = torchmetrics.JaccardIndex(task='multiclass', num_classes=num_classes).to(device)\n    confusion_matrix = torchmetrics.ConfusionMatrix(task='multiclass', num_classes=num_classes).to(device)\n\n    model.eval()\n\n    class_probs = {i: 0 for i in range(num_classes)}\n    num_samples = {i: 0 for i in range(num_classes)}\n\n    for X, y in test_loader:\n        X = X.to(device)\n        y = y.to(device)\n\n        with torch.no_grad():\n            logits = F.softmax(model(X), dim=1)  # Apply softmax to get probabilities\n            aggr = torch.max(logits, dim=1)  # Get the predicted class (index of the max probability)\n            preds = aggr[1]  # Predictions\n            probs = aggr[0]  # Probabilities of the predicted classes\n\n            # Update per-class probabilities and number of samples\n            for label in class_probs.keys():\n                class_probs[label] += probs[preds == label].sum().item()\n                num_samples[label] += (preds == label).sum().item()\n\n            # Update metrics\n            precision.update(preds, y)\n            recall.update(preds, y)\n            f1_score.update(preds, y)\n            acc.update(preds, y)\n            jaccard.update(preds, y)\n            confusion_matrix.update(preds, y)  # Update the confusion matrix with predictions and ground truth\n\n    # Normalize class probabilities\n    for label in class_probs.keys():\n        if num_samples[label] > 0:\n            class_probs[label] /= num_samples[label]\n\n    # Compute final metrics\n    precision_result = precision.compute()\n    recall_result = recall.compute()\n    f1_score_result = f1_score.compute()\n    acc_result = acc.compute()\n    jaccard_result = jaccard.compute()\n    confusion_matrix_result = confusion_matrix.compute()\n\n    return precision_result, recall_result, f1_score_result, confusion_matrix_result, acc_result, jaccard_result, class_probs\n\n\ndef plot_confusion_matrix(confusion_matrix, class_names):\n    \"\"\"\n    Plot the confusion matrix using Seaborn heatmap.\n    Args:\n        confusion_matrix: The confusion matrix to plot.\n        class_names: List of class names corresponding to the matrix indices.\n    \"\"\"\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(confusion_matrix.cpu().numpy(), annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted Label')\n    plt.ylabel('True Label')\n    plt.show()\n\n\ndef plot_multiclass_roc(model, test_loader, num_classes=5, device=\"cpu\"):\n    \"\"\"\n    Function to plot ROC curves for multi-class classification.\n    \n    Args:\n        model: The trained model.\n        test_loader: Dataloader for the test dataset.\n        num_classes: Number of classes.\n        device: Device to run the evaluation.\n    \"\"\"\n    y_true = []\n    y_scores = []\n\n    model.eval()\n    with torch.no_grad():\n        for X, y in test_loader:\n            X = X.to(device)\n            y = y.to(device)\n\n            logits = F.softmax(model(X), dim=1)\n            y_true.append(y.cpu())\n            y_scores.append(logits.cpu())\n\n    # Concatenate all batches\n    y_true = torch.cat(y_true).numpy()\n    y_scores = torch.cat(y_scores).numpy()\n\n    # Binarize labels for ROC\n    y_true_binarized = label_binarize(y_true, classes=[i for i in range(num_classes)])\n    \n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n\n    for i in range(num_classes):\n        fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], y_scores[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # Plotting all ROC curves\n    plt.figure(figsize=(10, 8))\n    for i in range(num_classes):\n        plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve of class {classes[i]} (area = {roc_auc[i]:.2f})')\n    \n    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic for Multi-Class')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n\n# Call the function to get metrics\nprecision, recall, f1_score, confusion_matrix, acc, jaccard, class_probs = segmentation_test_loop_with_metrics(\n    model=model_resnet101, test_loader=test_dloader, num_classes=5, device=device)\n\n# Print the metrics with class names\nprint(f\"{'Class':<15}{'Precision':<10}{'Recall':<10}{'F1-Score':<10}\")\nfor i, class_name in enumerate(classes):\n    print(f\"{class_name:<15}{precision[i].item():<10.4f}{recall[i].item():<10.4f}{f1_score[i].item():<10.4f}\")\nprint(f\"\\nAccuracy: {acc.item():.4f}\")\nprint(f\"Mean IoU (Jaccard Index): {jaccard.item():.4f}\")\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T03:11:44.286205Z","iopub.execute_input":"2024-09-25T03:11:44.286548Z","iopub.status.idle":"2024-09-25T03:12:25.669246Z","shell.execute_reply.started":"2024-09-25T03:11:44.286512Z","shell.execute_reply":"2024-09-25T03:12:25.668003Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot the confusion matrix\nplot_confusion_matrix(confusion_matrix, classes)","metadata":{"execution":{"iopub.status.busy":"2024-09-25T03:12:25.670776Z","iopub.execute_input":"2024-09-25T03:12:25.671268Z","iopub.status.idle":"2024-09-25T03:12:26.118989Z","shell.execute_reply.started":"2024-09-25T03:12:25.671219Z","shell.execute_reply":"2024-09-25T03:12:26.117987Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_multiclass_roc1(model, test_loader, num_classes=5, device=\"cpu\"):\n    \"\"\"\n    Function to plot ROC curves for multi-class classification.\n    \n    Args:\n        model: The trained model.\n        test_loader: Dataloader for the test dataset.\n        num_classes: Number of classes.\n        device: Device to run the evaluation.\n    \"\"\"\n    y_true = []\n    y_scores = []\n\n    model.eval()\n    with torch.no_grad():\n        for X, y in test_loader:\n            X = X.to(device)\n            y = y.to(device)\n\n            logits = F.softmax(model(X), dim=1)  # Get probability scores\n            y_true.append(y.cpu())  # True labels\n            y_scores.append(logits.cpu())  # Predicted probabilities\n\n    # Concatenate all batches to create full arrays of true labels and scores\n    y_true = torch.cat(y_true).numpy()  # Shape: (N,) for N samples\n    y_scores = torch.cat(y_scores).numpy()  # Shape: (N, num_classes)\n\n    # Binarize labels for ROC (needed for multi-class)\n    y_true_binarized = label_binarize(y_true, classes=[i for i in range(num_classes)])  # Shape: (N, num_classes)\n    \n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n\n    for i in range(num_classes):\n        fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], y_scores[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # Plotting all ROC curves\n    plt.figure(figsize=(10, 8))\n    for i in range(num_classes):\n        plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve of class {classes[i]} (area = {roc_auc[i]:.2f})')\n    \n    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic for Multi-Class')\n    plt.legend(loc=\"lower right\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-25T03:52:20.845685Z","iopub.execute_input":"2024-09-25T03:52:20.846724Z","iopub.status.idle":"2024-09-25T03:52:20.858711Z","shell.execute_reply.started":"2024-09-25T03:52:20.846681Z","shell.execute_reply":"2024-09-25T03:52:20.857778Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot ROC curve for multi-class classifier\nplot_multiclass_roc1(model=model_resnet101, test_loader=test_dloader, num_classes=5, device=device)","metadata":{"execution":{"iopub.status.busy":"2024-09-25T03:52:25.164729Z","iopub.execute_input":"2024-09-25T03:52:25.165142Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## resnet 152","metadata":{}},{"cell_type":"code","source":"model_resnet152 = smp.Unet(encoder_name = \"resnet152\",\n                encoder_weights = \"imagenet\",\n                classes = 5).to(device=\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-09-27T11:00:02.753049Z","iopub.execute_input":"2024-09-27T11:00:02.753807Z","iopub.status.idle":"2024-09-27T11:00:04.540384Z","shell.execute_reply.started":"2024-09-27T11:00:02.753757Z","shell.execute_reply":"2024-09-27T11:00:04.538967Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-09-27T11:00:32.884489Z","iopub.execute_input":"2024-09-27T11:00:32.885799Z","iopub.status.idle":"2024-09-27T11:00:45.071227Z","shell.execute_reply.started":"2024-09-27T11:00:32.885733Z","shell.execute_reply":"2024-09-27T11:00:45.069501Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchsummary import summary\nsummary(model_resnet152, input_size=(3, 512, 512), device=\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-09-27T11:00:49.981964Z","iopub.execute_input":"2024-09-27T11:00:49.982458Z","iopub.status.idle":"2024-09-27T11:00:55.496697Z","shell.execute_reply.started":"2024-09-27T11:00:49.982393Z","shell.execute_reply":"2024-09-27T11:00:55.495347Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\ntrainable_params = count_parameters(model_resnet152)\nprint(f\"Total trainable parameters: {trainable_params}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-25T04:00:49.508010Z","iopub.execute_input":"2024-09-25T04:00:49.508423Z","iopub.status.idle":"2024-09-25T04:00:49.517344Z","shell.execute_reply.started":"2024-09-25T04:00:49.508377Z","shell.execute_reply":"2024-09-25T04:00:49.516434Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from landcoverutil import training_loop\n\nepochs = 50\n\n# Training starts!\ntraining_loop(model_resnet152, train_dloader, val_dloader, epochs, lr, loss_fn, mod_epochs =1,\n             regularization = \"L2\", reg_lambda = 1e-6, early_stopping = False,\n             patience = 5, verbose = True, model_title = \"UNet with Resnet encoder 152\", save = True,\n             stopping_criterion = \"loss\")","metadata":{"execution":{"iopub.status.busy":"2024-09-25T04:00:49.518672Z","iopub.execute_input":"2024-09-25T04:00:49.519047Z","iopub.status.idle":"2024-09-25T11:06:55.869520Z","shell.execute_reply.started":"2024-09-25T04:00:49.519000Z","shell.execute_reply":"2024-09-25T11:06:55.868393Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def visualize_preds(model, train_set, title, num_samples = 4, seed = 42,\n                    w = 10, h = 10, save_title = None, indices = None):\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    np.random.seed(seed)\n    if indices == None:\n        indices = np.random.randint(low = 0, high = len(train_set),\n                                    size = num_samples)\n    sns.set_style(\"white\")\n    fig, ax = plt.subplots(figsize = (w,h),\n                           nrows = num_samples, ncols = 3)\n    model.eval()\n    for i,idx in enumerate(indices):\n        X,y = train_set[idx]\n        X_dash = X[None,:,:,:].to(device)\n        preds = torch.argmax(model(X_dash), dim = 1)\n        preds = torch.squeeze(preds).detach().cpu().numpy()\n\n        mirrored_img = np.fliplr(np.transpose(X.cpu(), (2,1,0)))  # Apply horizontal flip\n        rotated_mirrored_img = np.rot90(mirrored_img, k=1)  # Rotate 180 degrees (two 90-degree rotations)\n\n        # Display the mirrored and rotated image\n        ax[i,0].imshow(rotated_mirrored_img)\n        ax[i,0].set_title(\"True Image\")\n        ax[i,0].axis(\"off\")\n        ax[i,1].imshow(y, cmap = labels_cmap, interpolation = None,\n                      vmin = -0.5, vmax = 4.5)\n        ax[i,1].set_title(\"Labels\")\n        ax[i,1].axis(\"off\")\n        ax[i,2].imshow(preds, cmap = labels_cmap, interpolation = None,\n                      vmin = -0.5, vmax = 4.5)\n        ax[i,2].set_title(\"Predictions\")\n        ax[i,2].axis(\"off\")\n    fig.suptitle(title, fontsize = 20)\n    plt.tight_layout()\n    if save_title is not None:\n        plt.savefig(save_title + \".png\")\n    plt.show()\n\nvisualize_preds(model_resnet152, test_set, title = \"Predictions - UNet+Resnet152\",\n               save_title = \"UNet+Resnet152\", h = 12, w = 12, indices = [957,961,1476,1578])","metadata":{"execution":{"iopub.status.busy":"2024-09-25T11:06:55.872170Z","iopub.execute_input":"2024-09-25T11:06:55.872543Z","iopub.status.idle":"2024-09-25T11:06:59.917736Z","shell.execute_reply.started":"2024-09-25T11:06:55.872506Z","shell.execute_reply":"2024-09-25T11:06:59.916706Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torchmetrics\nimport torchvision.transforms.functional as TF\nimport torch.nn.functional as F\n\ndef segmentation_test_loop_with_metrics(model, test_loader, num_classes=5, device=\"cpu\"):\n    \"\"\"\n    Runs a test loop for the model on a test dataset, calculates precision, recall, F1-score, accuracy, IoU, and confusion matrix.\n\n    Args:\n        model: The trained model to evaluate.\n        test_loader: Dataloader for the test dataset.\n        num_classes: The number of classes in the dataset.\n        device: Device to run the evaluation on (\"cpu\" or \"cuda\").\n\n    Returns:\n        precision: Precision score for each class.\n        recall: Recall score for each class.\n        f1_score: F1 score for each class.\n        confusion_matrix: Computed confusion matrix.\n        acc: Overall accuracy.\n        jaccard: Jaccard index (IoU) for the entire test set.\n    \"\"\"\n\n    # Initialize metrics\n    precision = torchmetrics.Precision(task='multiclass', num_classes=num_classes, average=None).to(device)\n    recall = torchmetrics.Recall(task='multiclass', num_classes=num_classes, average=None).to(device)\n    f1_score = torchmetrics.F1Score(task='multiclass', num_classes=num_classes, average=None).to(device)\n    \n    # Additional metrics\n    acc = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes, average=\"micro\", multidim_average=\"global\").to(device)\n    jaccard = torchmetrics.JaccardIndex(task='multiclass', num_classes=num_classes).to(device)\n    confusion_matrix = torchmetrics.ConfusionMatrix(task='multiclass', num_classes=num_classes).to(device)\n\n    model.eval()\n\n    class_probs = {i: 0 for i in range(num_classes)}\n    num_samples = {i: 0 for i in range(num_classes)}\n\n    for X, y in test_loader:\n        X = X.to(device)\n        y = y.to(device)\n\n        with torch.no_grad():\n            logits = F.softmax(model(X), dim=1)  # Apply softmax to get probabilities\n            aggr = torch.max(logits, dim=1)  # Get the predicted class (index of the max probability)\n            preds = aggr[1]  # Predictions\n            probs = aggr[0]  # Probabilities of the predicted classes\n\n            # Update per-class probabilities and number of samples\n            for label in class_probs.keys():\n                class_probs[label] += probs[preds == label].sum().item()\n                num_samples[label] += (preds == label).sum().item()\n\n            # Update metrics\n            precision.update(preds, y)\n            recall.update(preds, y)\n            f1_score.update(preds, y)\n            acc.update(preds, y)\n            jaccard.update(preds, y)\n            confusion_matrix.update(preds, y)  # Update the confusion matrix with predictions and ground truth\n\n    # Normalize class probabilities\n    for label in class_probs.keys():\n        if num_samples[label] > 0:\n            class_probs[label] /= num_samples[label]\n\n    # Compute final metrics\n    precision_result = precision.compute()\n    recall_result = recall.compute()\n    f1_score_result = f1_score.compute()\n    acc_result = acc.compute()\n    jaccard_result = jaccard.compute()\n    confusion_matrix_result = confusion_matrix.compute()\n\n    return precision_result, recall_result, f1_score_result, confusion_matrix_result, acc_result, jaccard_result, class_probs\n\n\n# Call the function and get the metrics\nprecision, recall, f1_score, confusion_matrix, acc, jaccard, class_probs = segmentation_test_loop_with_metrics(\n    model=model_resnet152, test_loader=test_dloader, num_classes=5, device=device)\n\n# Print the metrics\nfor i in range(len(precision)):\n    print(f\"Class {i}: Precision: {precision[i].item():.4f}, Recall: {recall[i].item():.4f}, F1-Score: {f1_score[i].item():.4f}\")\nprint(f\"Confusion Matrix:\\n {confusion_matrix.cpu().numpy()}\")\nprint(f\"Accuracy: {acc.item():.4f}\")\nprint(f\"Jaccard Index (Mean IoU): {jaccard.item():.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T11:43:53.930159Z","iopub.execute_input":"2024-09-25T11:43:53.930852Z","iopub.status.idle":"2024-09-25T11:44:44.461641Z","shell.execute_reply.started":"2024-09-25T11:43:53.930789Z","shell.execute_reply":"2024-09-25T11:44:44.460328Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport torchmetrics\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import roc_curve, auc\n\n# Class labels for the segmentation task\nclasses = ['Building', 'Woodland', 'Water', 'Road', 'Unlabeled']\n\ndef segmentation_test_loop_with_metrics(model, test_loader, num_classes=5, device=\"cpu\"):\n    \"\"\"\n    Runs a test loop for the model on a test dataset, calculates precision, recall, F1-score, accuracy, IoU, and confusion matrix.\n    Additionally, calculates the per-class metrics and returns them for evaluation.\n    \n    Args:\n        model: The trained model to evaluate.\n        test_loader: Dataloader for the test dataset.\n        num_classes: The number of classes in the dataset.\n        device: Device to run the evaluation on (\"cpu\" or \"cuda\").\n\n    Returns:\n        precision: Precision score for each class.\n        recall: Recall score for each class.\n        f1_score: F1 score for each class.\n        confusion_matrix: Computed confusion matrix.\n        acc: Overall accuracy.\n        jaccard: Jaccard index (IoU) for the entire test set.\n        class_probs: The average probability for each class.\n    \"\"\"\n\n    # Initialize metrics\n    precision = torchmetrics.Precision(task='multiclass', num_classes=num_classes, average=None).to(device)\n    recall = torchmetrics.Recall(task='multiclass', num_classes=num_classes, average=None).to(device)\n    f1_score = torchmetrics.F1Score(task='multiclass', num_classes=num_classes, average=None).to(device)\n    \n    # Additional metrics\n    acc = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes, average=\"micro\", multidim_average=\"global\").to(device)\n    jaccard = torchmetrics.JaccardIndex(task='multiclass', num_classes=num_classes).to(device)\n    confusion_matrix = torchmetrics.ConfusionMatrix(task='multiclass', num_classes=num_classes).to(device)\n\n    model.eval()\n\n    class_probs = {i: 0 for i in range(num_classes)}\n    num_samples = {i: 0 for i in range(num_classes)}\n\n    for X, y in test_loader:\n        X = X.to(device)\n        y = y.to(device)\n\n        with torch.no_grad():\n            logits = F.softmax(model(X), dim=1)  # Apply softmax to get probabilities\n            aggr = torch.max(logits, dim=1)  # Get the predicted class (index of the max probability)\n            preds = aggr[1]  # Predictions\n            probs = aggr[0]  # Probabilities of the predicted classes\n\n            # Update per-class probabilities and number of samples\n            for label in class_probs.keys():\n                class_probs[label] += probs[preds == label].sum().item()\n                num_samples[label] += (preds == label).sum().item()\n\n            # Update metrics\n            precision.update(preds, y)\n            recall.update(preds, y)\n            f1_score.update(preds, y)\n            acc.update(preds, y)\n            jaccard.update(preds, y)\n            confusion_matrix.update(preds, y)  # Update the confusion matrix with predictions and ground truth\n\n    # Normalize class probabilities\n    for label in class_probs.keys():\n        if num_samples[label] > 0:\n            class_probs[label] /= num_samples[label]\n\n    # Compute final metrics\n    precision_result = precision.compute()\n    recall_result = recall.compute()\n    f1_score_result = f1_score.compute()\n    acc_result = acc.compute()\n    jaccard_result = jaccard.compute()\n    confusion_matrix_result = confusion_matrix.compute()\n\n    return precision_result, recall_result, f1_score_result, confusion_matrix_result, acc_result, jaccard_result, class_probs\n\n\ndef plot_confusion_matrix(confusion_matrix, class_names):\n    \"\"\"\n    Plot the confusion matrix using Seaborn heatmap.\n    Args:\n        confusion_matrix: The confusion matrix to plot.\n        class_names: List of class names corresponding to the matrix indices.\n    \"\"\"\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(confusion_matrix.cpu().numpy(), annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted Label')\n    plt.ylabel('True Label')\n    plt.show()\n\n\ndef plot_multiclass_roc(model, test_loader, num_classes=5, device=\"cpu\"):\n    \"\"\"\n    Function to plot ROC curves for multi-class classification.\n    \n    Args:\n        model: The trained model.\n        test_loader: Dataloader for the test dataset.\n        num_classes: Number of classes.\n        device: Device to run the evaluation.\n    \"\"\"\n    y_true = []\n    y_scores = []\n\n    model.eval()\n    with torch.no_grad():\n        for X, y in test_loader:\n            X = X.to(device)\n            y = y.to(device)\n\n            logits = F.softmax(model(X), dim=1)\n            y_true.append(y.cpu())\n            y_scores.append(logits.cpu())\n\n    # Concatenate all batches\n    y_true = torch.cat(y_true).numpy()\n    y_scores = torch.cat(y_scores).numpy()\n\n    # Binarize labels for ROC\n    y_true_binarized = label_binarize(y_true, classes=[i for i in range(num_classes)])\n    \n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n\n    for i in range(num_classes):\n        fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], y_scores[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # Plotting all ROC curves\n    plt.figure(figsize=(10, 8))\n    for i in range(num_classes):\n        plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve of class {classes[i]} (area = {roc_auc[i]:.2f})')\n    \n    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic for Multi-Class')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n\n# Call the function to get metrics\nprecision, recall, f1_score, confusion_matrix, acc, jaccard, class_probs = segmentation_test_loop_with_metrics(\n    model=model_resnet152, test_loader=test_dloader, num_classes=5, device=device)\n\n# Print the metrics with class names\nprint(f\"{'Class':<15}{'Precision':<10}{'Recall':<10}{'F1-Score':<10}\")\nfor i, class_name in enumerate(classes):\n    print(f\"{class_name:<15}{precision[i].item():<10.4f}{recall[i].item():<10.4f}{f1_score[i].item():<10.4f}\")\nprint(f\"\\nAccuracy: {acc.item():.4f}\")\nprint(f\"Mean IoU (Jaccard Index): {jaccard.item():.4f}\")\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T11:44:44.465329Z","iopub.execute_input":"2024-09-25T11:44:44.465663Z","iopub.status.idle":"2024-09-25T11:45:34.868196Z","shell.execute_reply.started":"2024-09-25T11:44:44.465629Z","shell.execute_reply":"2024-09-25T11:45:34.867016Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot the confusion matrix\nplot_confusion_matrix(confusion_matrix, classes)","metadata":{"execution":{"iopub.status.busy":"2024-09-25T11:45:34.869891Z","iopub.execute_input":"2024-09-25T11:45:34.870310Z","iopub.status.idle":"2024-09-25T11:45:35.323451Z","shell.execute_reply.started":"2024-09-25T11:45:34.870263Z","shell.execute_reply":"2024-09-25T11:45:35.322554Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef plot_multiclass_roc(model, test_loader, classes=['Building', 'Woodland', 'Water', 'Road', 'Unlabeled'], device=\"cpu\"):\n    \"\"\"\n    Function to plot ROC curves for multi-class classification.\n    \n    Args:\n        model: The trained model.\n        test_loader: Dataloader for the test dataset.\n        classes: List of class names.\n        device: Device to run the evaluation.\n    \"\"\"\n    num_classes = len(classes)\n    y_true = []\n    y_scores = []\n\n    model.eval()\n    with torch.no_grad():\n        for X, y in test_loader:\n            X = X.to(device)\n            y = y.to(device)\n\n            logits = F.softmax(model(X), dim=1)  # Get probability scores\n            y_true.append(y.cpu())  # True labels\n            y_scores.append(logits.cpu())  # Predicted probabilities\n\n    # Concatenate all batches to create full arrays of true labels and scores\n    y_true = torch.cat(y_true).numpy()  # Shape: (N, H, W) for N samples in segmentation\n    y_scores = torch.cat(y_scores).numpy()  # Shape: (N, num_classes, H, W)\n    \n    # Flatten both y_true and y_scores so that they are 1D arrays\n    y_true_flat = y_true.flatten()  # Shape: (N * H * W,)\n    y_scores_flat = y_scores.reshape(-1, num_classes)  # Shape: (N * H * W, num_classes)\n\n    # Binarize labels for ROC (needed for multi-class)\n    y_true_binarized = label_binarize(y_true_flat, classes=[i for i in range(num_classes)])  # Shape: (N * H * W, num_classes)\n    \n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n\n    for i in range(num_classes):\n        fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], y_scores_flat[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # Plotting all ROC curves\n    plt.figure(figsize=(10, 8))\n    for i in range(num_classes):\n        plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve of class {classes[i]} (area = {roc_auc[i]:.2f})')\n    \n    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic for Multi-Class')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T11:54:31.177983Z","iopub.execute_input":"2024-09-25T11:54:31.178439Z","iopub.status.idle":"2024-09-25T11:54:31.192589Z","shell.execute_reply.started":"2024-09-25T11:54:31.178397Z","shell.execute_reply":"2024-09-25T11:54:31.191538Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot ROC curve for multi-class classifier\nplot_multiclass_roc(model=model_resnet152, test_loader=test_dloader, device=device)","metadata":{"execution":{"iopub.status.busy":"2024-09-25T11:55:06.659991Z","iopub.execute_input":"2024-09-25T11:55:06.660406Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model_resnet152.state_dict(), \"resnet152.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-08-15T02:12:55.888315Z","iopub.execute_input":"2024-08-15T02:12:55.888600Z","iopub.status.idle":"2024-08-15T02:12:56.334664Z","shell.execute_reply.started":"2024-08-15T02:12:55.888576Z","shell.execute_reply":"2024-08-15T02:12:56.333745Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Thanks to Christos Nikou (https://github.com/ChrisNick92)","metadata":{}}]}